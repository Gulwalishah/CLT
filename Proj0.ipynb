{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcOyAb6EB/o7uraJQq5lVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gulwalishah/CLT/blob/main/Proj0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adoKSvBJz4V",
        "outputId": "9ac30d49-1bf6-43ad-948d-d5e83302f8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 75s 47ms/step - loss: 1.5565 - accuracy: 0.4330 - val_loss: 1.3273 - val_accuracy: 0.5193\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 1.1969 - accuracy: 0.5752 - val_loss: 1.1392 - val_accuracy: 0.5980\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.1392 - accuracy: 0.5980\n",
            "Test accuracy: 0.5979999899864197\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define CNN architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_images, train_labels, epochs=2, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "# Additional Techniques and Model Improvements:\n",
        "# 1. Data Augmentation:\n",
        "#    - Use data augmentation techniques like rotation, flipping, and shifting to generate additional training samples and improve model generalization.\n",
        "#    - TensorFlow provides the `ImageDataGenerator` class for implementing data augmentation easily.\n",
        "\n",
        "# 2. Dropout Regularization:\n",
        "#    - Apply dropout regularization to prevent overfitting by randomly dropping neurons during training.\n",
        "#    - Add dropout layers after convolutional and dense layers to reduce over-reliance on certain features.\n",
        "\n",
        "# 3. Transfer Learning:\n",
        "#    - Utilize pre-trained CNN models (e.g., VGG, ResNet, Inception) as feature extractors and fine-tune them on your dataset.\n",
        "#    - This approach is useful when you have limited training data or need to train models quickly.\n",
        "\n",
        "# 4. Learning Rate Scheduling:\n",
        "#    - Implement learning rate scheduling techniques such as exponential decay or step decay to adjust the learning rate during training.\n",
        "#    - This helps to stabilize training and potentially improve convergence to a better solution.\n",
        "\n",
        "# 5. Batch Normalization:\n",
        "#    - Incorporate batch normalization layers after convolutional and dense layers to stabilize training and accelerate convergence.\n",
        "#    - Batch normalization helps to mitigate issues like internal covariate shift and improve gradient flow.\n",
        "\n",
        "# 6. Hyperparameter Tuning:\n",
        "#    - Experiment with different hyperparameters such as learning rate, batch size, and optimizer choice to find the optimal configuration.\n",
        "#    - You can use techniques like grid search or random search for hyperparameter tuning.\n",
        "\n",
        "# 7. Model Ensemble:\n",
        "#    - Train multiple CNN models with different architectures or initializations and combine their predictions to improve performance.\n",
        "#    - Ensemble methods can help reduce variance and improve generalization of the model.\n",
        "\n",
        "# 8. Advanced Architectures:\n",
        "#    - Explore advanced CNN architectures like residual networks (ResNet), densely connected networks (DenseNet), or attention mechanisms (e.g., Transformer).\n",
        "#    - These architectures often achieve state-of-the-art performance on various image classification tasks.\n",
        "\n",
        "# 9. Model Interpretability:\n",
        "#    - Use techniques like gradient-weighted class activation mapping (Grad-CAM) to visualize and interpret the model's predictions.\n",
        "#    - Understanding which parts of the image contribute most to the model's decision can provide valuable insights into its behavior.\n"
      ]
    }
  ]
}